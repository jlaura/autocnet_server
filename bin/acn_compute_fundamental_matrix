#!/usr/bin/env python3

import copy
import os
import json
import sys
import time

import numpy as np
from redis import StrictRedis
from skimage.feature import register_translation
import yaml


#Load the config file
with open(os.environ['autocnet_config'], 'r') as f:
    config = yaml.load(f)

# Patch in dev. versions if requested.
acp = config.get('developer', {}).get('autocnet_path', None)
if acp:
    sys.path.insert(0, acp)

asp = config.get('developer', {}).get('autocnet_server_path', None)
if asp:
    sys.path.insert(0, asp)

pl = config.get('developer', {}).get('plio_path', None)
if pl:
    sys.path.insert(0, pl)

from plio.io.io_gdal import GeoDataset

from autocnet_server.db import connection
from autocnet_server.db.model import  Keypoints, Matches, Edges, Images
from autocnet_server.db.redis_queue import pop_computetime_push, finalize

from autocnet.utils.utils import get_size, getsubarr, correlation_coefficient
from autocnet.matcher.cpu_ring_matcher import ring_match, add_correspondences
from autocnet.transformation.fundamental_matrix import compute_fundamental_matrix


def main(msg):
    source_id = msg['sidx']
    destin_id = msg['didx']

    tolerance = msg['tolerance']
    reproj_threshold = msg['reproj_threshold']
    initial_x_size = msg['initial_x_size']
    initial_y_size = msg['initial_y_size']
    corr_x_size = msg['corr_x_size']
    corr_y_size = msg['corr_y_size']

    # Get the homogeneous keypoints and the image file paths
    print('Processing Edge: ({},{})'.format(source_id, destin_id))
    session, _ = connection.new_connection(config)
    res = session.query(Matches).filter(Matches.source == source_id,
                                            Matches.destination == destin_id).all()
    nmatches = len(res)
    spts = np.empty((nmatches, 2))
    dpts = np.empty((nmatches, 2))
    for i in range(nmatches):
        spts[i] = res[i].source_x, res[i].source_y
        dpts[i] = res[i].destination_x, res[i].destination_y

    simgfile = session.query(Images).filter(Images.id == source_id).first().path
    dimgfile = session.query(Images).filter(Images.id == destin_id).first().path
    session.close()

    source_geodata = GeoDataset(simgfile)
    destin_geodata = GeoDataset(dimgfile)

    # Subpixel register the dpts to the spts and flag misregistrations
    good = [] # good indices
    for i in range(nmatches):
        rpt = spts[i]
        tpt = dpts[i]
        xsize = initial_x_size
        ysize = initial_y_size

        # check to ensure that the ssub and dsub can be within in the image extent
        xsize, ysize = get_size(rpt[0], rpt[1], tpt[0], tpt[1], xsize, ysize,
                                source_geodata.raster_size,
                                destin_geodata.raster_size)
        ssub, axr, ayr = getsubarr(rpt[0], rpt[1], source_geodata, xsize=xsize, ysize=ysize)
        dsub, dxr, dyr = getsubarr(tpt[0], tpt[1], destin_geodata, xsize=xsize, ysize=ysize)
        (y_shift, x_shift), error, diffphase = register_translation(ssub, dsub,
                            upsample_factor=100,
                            space='real')  

        # Compute the NCC of sub-images centered on the new pt
        ntpt = [tpt[0] - x_shift + dxr, tpt[1] - y_shift + dyr]
        cxs,  cys = get_size(rpt[0], rpt[1], ntpt[0], ntpt[1],
                                             corr_x_size,  corr_y_size, 
                                             source_geodata.raster_size,
                                             destin_geodata.raster_size)
        stiny, _, _ = getsubarr(rpt[0], rpt[1], source_geodata, xsize=cxs, ysize= cys)
        dtiny, _, _ = getsubarr(ntpt[0], ntpt[1], destin_geodata, xsize=cxs, ysize= cys)
        cc = correlation_coefficient(stiny, dtiny)
        if cc >= tolerance:
            dpts[i] = ntpt
            good.append(i)
    subpixel_source = spts[good]
    subpixel_destin = dpts[good]

    original_mask = np.zeros(nmatches, dtype=np.bool)

    F, mask = compute_fundamental_matrix(subpixel_source, subpixel_destin,
                                         reproj_threshold=reproj_threshold,
                                         method='ransac')

    # Update full size mask with the True values that come out of the F matrix computation
    original_mask[good] = mask
    print(original_mask)
    if F is not None:
        msg['success'] = True
    return msg, (source_id, destin_id, F, original_mask, dpts)

def write_to_db(sourceid, destinid, fmatrix, mask, subpixel_destin):
    session, _ = connection.new_connection(config)
    session.begin()
    if fmatrix is not None:
        edge = session.query(Edges).filter(Edges.source == sourceid, Edges.destination == destinid).first()
        setattr(edge, 'fundamental', fmatrix)

    # Update the matches dataframe here to set valid=False 
    # for any points that were fundamental masked.

    # TODO: Masking
    matches = session.query(Matches).filter(Matches.source == sourceid,
                                            Matches.destination == destinid)
    for i, m in enumerate(matches):
        m.valid = bool(mask[i]) # SQLAlchemy does not support numpy bools
        m.destination_x = subpixel_destin[i][0]
        m.destination_y = subpixel_destin[i][1]
    session.commit()
    session.close()

if __name__ == '__main__':
    queue = StrictRedis( host="smalls", port=8000, db=0)
    msg = pop_computetime_push(queue,
                            config['redis']['processing_queue'],
                            config['redis']['working_queue'])

    remove_key = copy.deepcopy(msg)
    
    # Apply main
    response, to_db = main(msg)

    write_to_db(*to_db)
    # Alert the caller on failure to relaunch with next parameter set
    finalize(response, remove_key, queue, 
             config['redis']['completed_queue'],
             config['redis']['working_queue'])
